{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load Boston Housing dataset\n",
    "boston = fetch_openml(name='boston', version=2)\n",
    "\n",
    "# Create a DataFrame\n",
    "boston_df = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "boston_df['MEDV'] = boston.target  # Median value of owner-occupied homes (target variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3   \n",
       "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8   \n",
       "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8   \n",
       "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7   \n",
       "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7   \n",
       "\n",
       "        B  LSTAT MEDV  \n",
       "0  396.90   4.98    N  \n",
       "1  396.90   9.14    P  \n",
       "2  392.83   4.03    N  \n",
       "3  394.63   2.94    N  \n",
       "4  396.90   5.33    N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example using seaborn\n",
    "sns.boxplot(x=\"MEDV\", y='AGE', data=boston_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df=boston_df[['INDUS', 'AGE', 'MEDV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aadit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDUS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MEDV_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.31</td>\n",
       "      <td>65.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.07</td>\n",
       "      <td>78.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.07</td>\n",
       "      <td>61.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.18</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.18</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDUS   AGE  MEDV_P\n",
       "0   2.31  65.2       0\n",
       "1   7.07  78.9       1\n",
       "2   7.07  61.1       0\n",
       "3   2.18  45.8       0\n",
       "4   2.18  54.2       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Replace 'Categorical_Column' with the actual name of your categorical column\n",
    "\n",
    "# Convert the categorical column to binary using one-hot encoding\n",
    "boston_df = pd.get_dummies(boston_df, columns=['MEDV'], drop_first=True)\n",
    "\n",
    "\n",
    "# Replace True/False values with 1/0\n",
    "boston_df.replace({True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "boston_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the Pandas DataFrame into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = boston_df.drop('MEDV_P', axis=1)\n",
    "y = boston_df['MEDV_P']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('relu', 'relu', 'relu') configuration: 0.7745098039215687\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Test Accuracy with ('relu', 'relu', 'tanh') configuration: 0.6372549019607843\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('relu', 'relu', 'linear') configuration: 0.7745098039215687\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('relu', 'tanh', 'relu') configuration: 0.7843137254901961\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('relu', 'tanh', 'tanh') configuration: 0.6372549019607843\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Test Accuracy with ('relu', 'tanh', 'linear') configuration: 0.7843137254901961\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('relu', 'linear', 'relu') configuration: 0.7843137254901961\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('relu', 'linear', 'tanh') configuration: 0.7843137254901961\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('relu', 'linear', 'linear') configuration: 0.7745098039215687\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('tanh', 'relu', 'relu') configuration: 0.8137254901960784\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('tanh', 'relu', 'tanh') configuration: 0.8137254901960784\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Test Accuracy with ('tanh', 'relu', 'linear') configuration: 0.803921568627451\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('tanh', 'tanh', 'relu') configuration: 0.803921568627451\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('tanh', 'tanh', 'tanh') configuration: 0.7941176470588235\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('tanh', 'tanh', 'linear') configuration: 0.7647058823529411\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('tanh', 'linear', 'relu') configuration: 0.7549019607843137\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('tanh', 'linear', 'tanh') configuration: 0.7941176470588235\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('tanh', 'linear', 'linear') configuration: 0.8235294117647058\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('linear', 'relu', 'relu') configuration: 0.7941176470588235\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('linear', 'relu', 'tanh') configuration: 0.7647058823529411\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('linear', 'relu', 'linear') configuration: 0.7843137254901961\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('linear', 'tanh', 'relu') configuration: 0.7941176470588235\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('linear', 'tanh', 'tanh') configuration: 0.7647058823529411\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Test Accuracy with ('linear', 'tanh', 'linear') configuration: 0.8235294117647058\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Test Accuracy with ('linear', 'linear', 'relu') configuration: 0.7941176470588235\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('linear', 'linear', 'tanh') configuration: 0.7941176470588235\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Test Accuracy with ('linear', 'linear', 'linear') configuration: 0.7843137254901961\n",
      "Sorted Results:\n",
      "{('tanh', 'linear', 'linear'): 0.8235294117647058, ('linear', 'tanh', 'linear'): 0.8235294117647058, ('tanh', 'relu', 'relu'): 0.8137254901960784, ('tanh', 'relu', 'tanh'): 0.8137254901960784, ('tanh', 'relu', 'linear'): 0.803921568627451, ('tanh', 'tanh', 'relu'): 0.803921568627451, ('tanh', 'tanh', 'tanh'): 0.7941176470588235, ('tanh', 'linear', 'tanh'): 0.7941176470588235, ('linear', 'relu', 'relu'): 0.7941176470588235, ('linear', 'tanh', 'relu'): 0.7941176470588235, ('linear', 'linear', 'relu'): 0.7941176470588235, ('linear', 'linear', 'tanh'): 0.7941176470588235, ('relu', 'tanh', 'relu'): 0.7843137254901961, ('relu', 'tanh', 'linear'): 0.7843137254901961, ('relu', 'linear', 'relu'): 0.7843137254901961, ('relu', 'linear', 'tanh'): 0.7843137254901961, ('linear', 'relu', 'linear'): 0.7843137254901961, ('linear', 'linear', 'linear'): 0.7843137254901961, ('relu', 'relu', 'relu'): 0.7745098039215687, ('relu', 'relu', 'linear'): 0.7745098039215687, ('relu', 'linear', 'linear'): 0.7745098039215687, ('tanh', 'tanh', 'linear'): 0.7647058823529411, ('linear', 'relu', 'tanh'): 0.7647058823529411, ('linear', 'tanh', 'tanh'): 0.7647058823529411, ('tanh', 'linear', 'relu'): 0.7549019607843137, ('relu', 'relu', 'tanh'): 0.6372549019607843, ('relu', 'tanh', 'tanh'): 0.6372549019607843}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def build_model(activation_config, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation=activation_config[0], input_shape=(input_shape,)))\n",
    "\n",
    "    for activation_func in activation_config[1:]:\n",
    "        model.add(Dense(8, activation=activation_func))\n",
    "\n",
    "    model.add(Dense(8, activation='relu'))  # Assuming you want a specific activation for the last hidden layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, activation_config, batch_size=32, epochs=5, validation_split=0.2):\n",
    "    model = build_model(activation_config, X_train.shape[1])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=0)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    return test_accuracy\n",
    "\n",
    "def generate_combinations(activation_functions, num_layers):\n",
    "    return list(itertools.product(activation_functions, repeat=num_layers))\n",
    "\n",
    "def evaluate_all_combinations(X_train, y_train, X_test, y_test, activation_functions, num_layers, batch_size=32, epochs=5, validation_split=0.2):\n",
    "    combinations = generate_combinations(activation_functions, num_layers)\n",
    "    results = {}\n",
    "\n",
    "    for config in combinations:\n",
    "        accuracy = train_and_evaluate(X_train, y_train, X_test, y_test, config, batch_size=batch_size, epochs=epochs, validation_split=validation_split)\n",
    "        results[config] = accuracy\n",
    "        print(f'Test Accuracy with {config} configuration: {accuracy}')\n",
    "\n",
    "    # Sort the results based on accuracy in descending order\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return sorted_results\n",
    "\n",
    "\n",
    "# Specify activation functions and number of layers\n",
    "activation_functions = ['relu', 'tanh', 'linear']\n",
    "num_layers = 3\n",
    "\n",
    "# Evaluate all combinations\n",
    "results = evaluate_all_combinations(X_train, y_train, X_test, y_test, activation_functions, num_layers)\n",
    "print(\"Sorted Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
